{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegNet For Denoising 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "training_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'splitted_dataset_2.npz'\n",
    "dataset = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = dataset['inputs_train_1']\n",
    "cleans_train = dataset['cleans_train_1']\n",
    "inputs_test  = dataset['inputs_test_1']\n",
    "cleans_test  = dataset['cleans_test_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 2, 257, 382)\n",
      "(1800, 2, 257, 382)\n",
      "(200, 2, 257, 382)\n",
      "(200, 2, 257, 382)\n"
     ]
    }
   ],
   "source": [
    "print(inputs_train.shape)\n",
    "print(cleans_train.shape)\n",
    "print(inputs_test.shape)\n",
    "print(cleans_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder_dataset(Dataset):\n",
    "    def __init__(self, inputs, cleans):\n",
    "        self.inputs = torch.from_numpy(inputs).float()\n",
    "        self.cleans = torch.from_numpy(cleans).float()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.inputs[index]\n",
    "        cleans = self.cleans[index]\n",
    "        return inputs, cleans\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = AutoEncoder_dataset(inputs = inputs_train,\n",
    "                                cleans = cleans_train)\n",
    "test_set  = AutoEncoder_dataset(inputs = inputs_test,\n",
    "                                cleans = cleans_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        \n",
    "        self.Enc_0_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_1_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_2_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels= 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_2_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels= 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_3_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels= 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_3_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels= 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_4_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels= 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Enc_4_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels= 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        # Decoder\n",
    "        \n",
    "        self.Dec_4_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_4_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_3_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_3_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_2_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_2_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_1_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Dec_0_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.Unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # Encoder\n",
    "        \n",
    "        dim_0 = inputs.size()\n",
    "        outputs = self.Enc_0_1(inputs)\n",
    "        outputs, indice_0 = self.Pool(outputs)\n",
    "        \n",
    "        dim_1 = outputs.size()\n",
    "        outputs = self.Enc_1_1(outputs)\n",
    "        outputs, indice_1 = self.Pool(outputs)\n",
    "        \n",
    "        dim_2 = outputs.size()\n",
    "        outputs = self.Enc_2_1(outputs)\n",
    "        outputs = self.Enc_2_2(outputs)\n",
    "        outputs, indice_2 = self.Pool(outputs)\n",
    "        \n",
    "        dim_3 = outputs.size()\n",
    "        outputs = self.Enc_3_1(outputs)\n",
    "        outputs = self.Enc_3_2(outputs)\n",
    "        outputs, indice_3 = self.Pool(outputs)\n",
    "        \n",
    "        dim_4 = outputs.size()\n",
    "        outputs = self.Enc_4_1(outputs)\n",
    "        outputs = self.Enc_4_2(outputs)\n",
    "        outputs, indice_4 = self.Pool(outputs)\n",
    "        \n",
    "        dim_middle = outputs.size()\n",
    "        \n",
    "        # Decoder\n",
    "        outputs = self.Unpool(outputs, indice_4, output_size=dim_4)\n",
    "        outputs = self.Dec_4_2(outputs)\n",
    "        outputs = self.Dec_4_1(outputs)\n",
    "        dim_4d = outputs.size()\n",
    "        \n",
    "        outputs = self.Unpool(outputs, indice_3, output_size=dim_3)\n",
    "        outputs = self.Dec_3_2(outputs)\n",
    "        outputs = self.Dec_3_1(outputs)\n",
    "        dim_3d = outputs.size()\n",
    "        \n",
    "        outputs = self.Unpool(outputs, indice_2, output_size=dim_2)\n",
    "        outputs = self.Dec_2_2(outputs)\n",
    "        outputs = self.Dec_2_1(outputs)\n",
    "        dim_2d = outputs.size()\n",
    "        \n",
    "        outputs = self.Unpool(outputs, indice_1, output_size=dim_1)\n",
    "        outputs = self.Dec_1_1(outputs)\n",
    "        dim_1d = outputs.size()\n",
    "        \n",
    "        outputs = self.Unpool(outputs, indice_0, output_size=dim_0)\n",
    "        outputs = self.Dec_0_1(outputs)\n",
    "        dim_0d = outputs.size()\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currernt cuda device  7\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 7\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Currernt cuda device ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(GPU_NUM))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, filename):\n",
    "    state = {\n",
    "        'Epoch': epoch,\n",
    "        'State_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :   10 / 300] cost = 9.08768707e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   20 / 300] cost = 8.69568175e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   30 / 300] cost = 8.68895149e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   40 / 300] cost = 8.61078952e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   50 / 300] cost = 8.61536755e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   60 / 300] cost = 8.59345309e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   70 / 300] cost = 8.58029816e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   80 / 300] cost = 8.32959413e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :   90 / 300] cost = 4.06738945e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  100 / 300] cost = 3.265536e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  110 / 300] cost = 3.137155e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  120 / 300] cost = 2.51261536e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  130 / 300] cost = 8.66508053e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  140 / 300] cost = 4.02044934e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  150 / 300] cost = 2.73251626e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  160 / 300] cost = 2.39072542e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  170 / 300] cost = 2.07909598e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  180 / 300] cost = 1.88174326e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  190 / 300] cost = 1.65727433e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  200 / 300] cost = 1.53772762e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  210 / 300] cost = 1.41123373e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  220 / 300] cost = 1.33512694e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  230 / 300] cost = 1.24458393e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  240 / 300] cost = 1.18663074e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  250 / 300] cost = 1.10405135e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  260 / 300] cost = 1.06502393e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  270 / 300] cost = 1.00187117e-05\n",
      "======= Saved Model =======\n",
      "[Epoch :  280 / 300] cost = 9.62407466e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  290 / 300] cost = 8.73902627e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  300 / 300] cost = 8.34913226e-06\n",
      "======= Saved Model =======\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i, (inputs, cleans) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        cleans = cleans.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = net(inputs)\n",
    "        cost = criterion(hypothesis, cleans)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "    if epoch % 10 == 9:\n",
    "        print('[Epoch : {:>4} / {:>3}] cost = {:>.9}'.format(epoch + 1, training_epochs, avg_cost))\n",
    "        \n",
    "        save_checkpoint(epoch, net, optimizer, 'SegNet.pt')\n",
    "        print(\"======= Saved Model =======\")\n",
    "        \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :  310 / 600] cost = 7.92656738e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  320 / 600] cost = 7.68245172e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  330 / 600] cost = 7.30007196e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  340 / 600] cost = 7.18075762e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  350 / 600] cost = 6.58737827e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  360 / 600] cost = 6.51382925e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  370 / 600] cost = 6.5266081e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  380 / 600] cost = 5.90251193e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  390 / 600] cost = 6.07209404e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  400 / 600] cost = 5.67085726e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  410 / 600] cost = 5.75515742e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  420 / 600] cost = 5.45606599e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  430 / 600] cost = 5.22341634e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  440 / 600] cost = 4.8399811e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  450 / 600] cost = 4.96169741e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  460 / 600] cost = 4.86766157e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  470 / 600] cost = 4.59064131e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  480 / 600] cost = 4.47630327e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  490 / 600] cost = 4.45678506e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  500 / 600] cost = 4.3254563e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  510 / 600] cost = 4.34647109e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  520 / 600] cost = 3.98963948e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  530 / 600] cost = 4.110193e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  540 / 600] cost = 4.16350576e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  550 / 600] cost = 3.96915493e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  560 / 600] cost = 3.77114975e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  570 / 600] cost = 3.68142037e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  580 / 600] cost = 3.66710128e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  590 / 600] cost = 3.69875897e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  600 / 600] cost = 3.58970101e-06\n",
      "======= Saved Model =======\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i, (inputs, cleans) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        cleans = cleans.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = net(inputs)\n",
    "        cost = criterion(hypothesis, cleans)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "    if epoch % 10 == 9:\n",
    "        print('[Epoch : {:>4} / {:>3}] cost = {:>.9}'.format(epoch + 1 + 300, training_epochs + 300, avg_cost))\n",
    "        \n",
    "        save_checkpoint(epoch, net, optimizer, 'SegNet.pt')\n",
    "        print(\"======= Saved Model =======\")\n",
    "        \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :  610 / 900] cost = 3.62000992e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  620 / 900] cost = 3.39115286e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  630 / 900] cost = 3.57259933e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  640 / 900] cost = 3.43366332e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  650 / 900] cost = 3.27461976e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  660 / 900] cost = 3.28709484e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  670 / 900] cost = 3.32075092e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  680 / 900] cost = 3.10164955e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  690 / 900] cost = 3.09115467e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  700 / 900] cost = 3.05063372e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  710 / 900] cost = 2.99575504e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  720 / 900] cost = 3.09315897e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  730 / 900] cost = 3.01417913e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  740 / 900] cost = 2.93542917e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  750 / 900] cost = 2.97043312e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  760 / 900] cost = 2.94240863e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  770 / 900] cost = 2.78513926e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  780 / 900] cost = 2.84165117e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  790 / 900] cost = 2.89805826e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  800 / 900] cost = 2.70354553e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  810 / 900] cost = 2.84197426e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  820 / 900] cost = 2.76800802e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  830 / 900] cost = 2.70242663e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  840 / 900] cost = 2.72264379e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  850 / 900] cost = 2.90673074e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  860 / 900] cost = 2.63375614e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  870 / 900] cost = 2.5417562e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  880 / 900] cost = 2.53506209e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  890 / 900] cost = 2.54552538e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  900 / 900] cost = 2.51099073e-06\n",
      "======= Saved Model =======\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i, (inputs, cleans) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        cleans = cleans.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = net(inputs)\n",
    "        cost = criterion(hypothesis, cleans)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "    if epoch % 10 == 9:\n",
    "        print('[Epoch : {:>4} / {:>3}] cost = {:>.9}'.format(epoch + 1 + 600, training_epochs + 600, avg_cost))\n",
    "        \n",
    "        save_checkpoint(epoch, net, optimizer, 'SegNet.pt')\n",
    "        print(\"======= Saved Model =======\")\n",
    "        \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :  910 / 1200] cost = 2.5854747e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  920 / 1200] cost = 2.67442238e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  930 / 1200] cost = 2.42542092e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  940 / 1200] cost = 2.73721412e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  950 / 1200] cost = 2.45288334e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  960 / 1200] cost = 2.44686544e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  970 / 1200] cost = 2.44471516e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  980 / 1200] cost = 2.4071212e-06\n",
      "======= Saved Model =======\n",
      "[Epoch :  990 / 1200] cost = 2.35924267e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1000 / 1200] cost = 2.39693395e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1010 / 1200] cost = 2.29529178e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1020 / 1200] cost = 2.24501537e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1030 / 1200] cost = 2.27298028e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1040 / 1200] cost = 2.30951696e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1050 / 1200] cost = 2.53698295e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1060 / 1200] cost = 2.30268756e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1070 / 1200] cost = 2.34689628e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1080 / 1200] cost = 2.2072004e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1090 / 1200] cost = 2.13799103e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1100 / 1200] cost = 2.09523682e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1110 / 1200] cost = 2.11404654e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1120 / 1200] cost = 2.07945027e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1130 / 1200] cost = 2.11747556e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1140 / 1200] cost = 2.18000059e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1150 / 1200] cost = 2.19427852e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1160 / 1200] cost = 2.04281719e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1170 / 1200] cost = 2.13199064e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1180 / 1200] cost = 2.02581964e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1190 / 1200] cost = 2.01317857e-06\n",
      "======= Saved Model =======\n",
      "[Epoch : 1200 / 1200] cost = 2.09120412e-06\n",
      "======= Saved Model =======\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i, (inputs, cleans) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        cleans = cleans.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = net(inputs)\n",
    "        cost = criterion(hypothesis, cleans)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "    if epoch % 10 == 9:\n",
    "        print('[Epoch : {:>4} / {:>3}] cost = {:>.9}'.format(epoch + 1 + 900, training_epochs + 900, avg_cost))\n",
    "        \n",
    "        save_checkpoint(epoch, net, optimizer, 'SegNet2.pt')\n",
    "        print(\"======= Saved Model =======\")\n",
    "        \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
