{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'splitted_dataset.npz'\n",
    "dataset = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputs_train',\n",
       " 'inputs_test',\n",
       " 'inputs_valid',\n",
       " 'labels_train',\n",
       " 'labels_test',\n",
       " 'labels_valid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = dataset['inputs_train']\n",
    "inputs_test  = dataset['inputs_test']\n",
    "inputs_valid = dataset['inputs_valid']\n",
    "labels_train = dataset['labels_train']\n",
    "labels_test  = dataset['labels_test']\n",
    "labels_valid = dataset['labels_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = torch.from_numpy(inputs).float()\n",
    "        self.labels = torch.from_numpy(labels).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.inputs[index]\n",
    "        labels = self.labels[index]\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Custom_dataset(inputs = inputs_train,\n",
    "                           labels = labels_train)\n",
    "test_set  = Custom_dataset(inputs = inputs_test,\n",
    "                           labels = labels_test)\n",
    "valid_set = Custom_dataset(inputs = inputs_valid,\n",
    "                           labels = labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader  = DataLoader(dataset=test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "valid_loader = DataLoader(dataset=valid_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.Features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3)\n",
    "            )\n",
    "        self.FC1 = nn.Linear(in_features=768, out_features=768, bias=True)\n",
    "        self.FC2 = nn.Linear(in_features=768, out_features=11, bias=True)\n",
    "        torch.nn.init.kaiming_normal_(self.FC1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.FC2.weight)\n",
    "        self.Classifier = nn.Sequential(\n",
    "            self.FC1,\n",
    "            nn.Dropout(p=0.5),\n",
    "            self.FC2\n",
    "            )\n",
    "    def forward(self, inputs):\n",
    "        output = self.Features(inputs)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.Classifier(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currernt cuda device  7\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 7\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Currernt cuda device ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(GPU_NUM))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define acc_check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_check(Net, dataset, epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataset:\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = Net(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc = (100 * correct / total)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :    1] \n",
      "cost = 2.41553211 \tAcc_Test  : 7.5 \tAcc_Train : 10.3\n",
      "[Epoch :    2] \n",
      "cost = 2.40173554 \tAcc_Test  : 13.5 \tAcc_Train : 11.6\n",
      "[Epoch :    3] \n",
      "cost = 2.39594626 \tAcc_Test  : 11.0 \tAcc_Train : 10.9\n",
      "[Epoch :    4] \n",
      "cost = 2.39214087 \tAcc_Test  : 8.5 \tAcc_Train : 11.3\n",
      "[Epoch :    5] \n",
      "cost = 2.39472747 \tAcc_Test  : 11.5 \tAcc_Train : 11.2\n",
      "[Epoch :    6] \n",
      "cost = 2.39040732 \tAcc_Test  : 11.0 \tAcc_Train : 10.7\n",
      "[Epoch :    7] \n",
      "cost = 2.38709807 \tAcc_Test  : 13.0 \tAcc_Train : 12.6\n",
      "[Epoch :    8] \n",
      "cost = 2.38593602 \tAcc_Test  : 12.5 \tAcc_Train : 13.7\n",
      "[Epoch :    9] \n",
      "cost = 2.37167287 \tAcc_Test  : 12.5 \tAcc_Train : 13.2\n",
      "[Epoch :   10] \n",
      "cost = 2.36676788 \tAcc_Test  : 12.5 \tAcc_Train : 13.4\n",
      "[Epoch :   11] \n",
      "cost = 2.37122369 \tAcc_Test  : 13.5 \tAcc_Train : 13.3\n",
      "[Epoch :   12] \n",
      "cost = 2.3629899 \tAcc_Test  : 15.0 \tAcc_Train : 13.4\n",
      "[Epoch :   13] \n",
      "cost = 2.35128903 \tAcc_Test  : 12.0 \tAcc_Train : 14.2\n",
      "[Epoch :   14] \n",
      "cost = 2.32386994 \tAcc_Test  : 10.5 \tAcc_Train : 13.7\n",
      "[Epoch :   15] \n",
      "cost = 2.30322671 \tAcc_Test  : 13.0 \tAcc_Train : 18.0\n",
      "[Epoch :   16] \n",
      "cost = 2.26232314 \tAcc_Test  : 14.5 \tAcc_Train : 20.3\n",
      "[Epoch :   17] \n",
      "cost = 2.24636006 \tAcc_Test  : 18.0 \tAcc_Train : 20.4\n",
      "[Epoch :   18] \n",
      "cost = 2.1878407 \tAcc_Test  : 17.0 \tAcc_Train : 22.8\n",
      "[Epoch :   19] \n",
      "cost = 2.17919207 \tAcc_Test  : 13.5 \tAcc_Train : 21.4\n",
      "[Epoch :   20] \n",
      "cost = 2.11775303 \tAcc_Test  : 19.0 \tAcc_Train : 25.8\n",
      "[Epoch :   21] \n",
      "cost = 2.05074763 \tAcc_Test  : 19.0 \tAcc_Train : 27.0\n",
      "[Epoch :   22] \n",
      "cost = 1.94690692 \tAcc_Test  : 23.0 \tAcc_Train : 26.3\n",
      "[Epoch :   23] \n",
      "cost = 1.90894699 \tAcc_Test  : 22.5 \tAcc_Train : 32.3\n",
      "[Epoch :   24] \n",
      "cost = 1.81068325 \tAcc_Test  : 25.0 \tAcc_Train : 32.3\n",
      "[Epoch :   25] \n",
      "cost = 1.75860918 \tAcc_Test  : 23.5 \tAcc_Train : 32.0\n",
      "[Epoch :   26] \n",
      "cost = 1.76107299 \tAcc_Test  : 22.5 \tAcc_Train : 37.8\n",
      "[Epoch :   27] \n",
      "cost = 1.65792418 \tAcc_Test  : 24.5 \tAcc_Train : 36.6\n",
      "[Epoch :   28] \n",
      "cost = 1.60004127 \tAcc_Test  : 24.0 \tAcc_Train : 38.8\n",
      "[Epoch :   29] \n",
      "cost = 1.56006396 \tAcc_Test  : 23.0 \tAcc_Train : 41.7\n",
      "[Epoch :   30] \n",
      "cost = 1.52719331 \tAcc_Test  : 27.0 \tAcc_Train : 43.9\n",
      "[Epoch :   31] \n",
      "cost = 1.49096119 \tAcc_Test  : 29.0 \tAcc_Train : 48.4\n",
      "[Epoch :   32] \n",
      "cost = 1.42359424 \tAcc_Test  : 24.0 \tAcc_Train : 47.0\n",
      "[Epoch :   33] \n",
      "cost = 1.40363061 \tAcc_Test  : 26.5 \tAcc_Train : 50.4\n",
      "[Epoch :   34] \n",
      "cost = 1.3811059 \tAcc_Test  : 33.0 \tAcc_Train : 49.0\n",
      "[Epoch :   35] \n",
      "cost = 1.3165009 \tAcc_Test  : 24.5 \tAcc_Train : 54.8\n",
      "[Epoch :   36] \n",
      "cost = 1.22438514 \tAcc_Test  : 27.5 \tAcc_Train : 54.3\n",
      "[Epoch :   37] \n",
      "cost = 1.20016789 \tAcc_Test  : 31.5 \tAcc_Train : 58.2\n",
      "[Epoch :   38] \n",
      "cost = 1.18678534 \tAcc_Test  : 26.0 \tAcc_Train : 56.9\n",
      "[Epoch :   39] \n",
      "cost = 1.1033088 \tAcc_Test  : 29.0 \tAcc_Train : 60.3\n",
      "[Epoch :   40] \n",
      "cost = 1.09169304 \tAcc_Test  : 33.0 \tAcc_Train : 60.3\n",
      "[Epoch :   41] \n",
      "cost = 0.98811096 \tAcc_Test  : 32.0 \tAcc_Train : 65.5\n",
      "[Epoch :   42] \n",
      "cost = 0.941010416 \tAcc_Test  : 29.5 \tAcc_Train : 66.9\n",
      "[Epoch :   43] \n",
      "cost = 0.904765487 \tAcc_Test  : 30.5 \tAcc_Train : 69.0\n",
      "[Epoch :   44] \n",
      "cost = 0.909877777 \tAcc_Test  : 25.5 \tAcc_Train : 60.4\n",
      "[Epoch :   45] \n",
      "cost = 0.880781293 \tAcc_Test  : 28.0 \tAcc_Train : 71.2\n",
      "[Epoch :   46] \n",
      "cost = 0.804778516 \tAcc_Test  : 30.0 \tAcc_Train : 74.3\n",
      "[Epoch :   47] \n",
      "cost = 0.753656924 \tAcc_Test  : 34.0 \tAcc_Train : 75.8\n",
      "[Epoch :   48] \n",
      "cost = 0.67083621 \tAcc_Test  : 35.5 \tAcc_Train : 78.1\n",
      "[Epoch :   49] \n",
      "cost = 0.628328681 \tAcc_Test  : 33.0 \tAcc_Train : 79.2\n",
      "[Epoch :   50] \n",
      "cost = 0.653710723 \tAcc_Test  : 32.0 \tAcc_Train : 81.4\n",
      "[Epoch :   51] \n",
      "cost = 0.603782952 \tAcc_Test  : 33.0 \tAcc_Train : 80.3\n",
      "[Epoch :   52] \n",
      "cost = 0.556785762 \tAcc_Test  : 35.5 \tAcc_Train : 83.1\n",
      "[Epoch :   53] \n",
      "cost = 0.52149725 \tAcc_Test  : 35.0 \tAcc_Train : 85.8\n",
      "[Epoch :   54] \n",
      "cost = 0.463591903 \tAcc_Test  : 35.5 \tAcc_Train : 85.4\n",
      "[Epoch :   55] \n",
      "cost = 0.458725512 \tAcc_Test  : 32.5 \tAcc_Train : 87.0\n",
      "[Epoch :   56] \n",
      "cost = 0.433553487 \tAcc_Test  : 36.5 \tAcc_Train : 86.1\n",
      "[Epoch :   57] \n",
      "cost = 0.429178894 \tAcc_Test  : 35.5 \tAcc_Train : 89.3\n",
      "[Epoch :   58] \n",
      "cost = 0.352389306 \tAcc_Test  : 37.5 \tAcc_Train : 91.5\n",
      "[Epoch :   59] \n",
      "cost = 0.354323119 \tAcc_Test  : 29.0 \tAcc_Train : 90.0\n",
      "[Epoch :   60] \n",
      "cost = 0.313024282 \tAcc_Test  : 38.5 \tAcc_Train : 87.9\n",
      "[Epoch :   61] \n",
      "cost = 0.316229224 \tAcc_Test  : 35.0 \tAcc_Train : 91.1\n",
      "[Epoch :   62] \n",
      "cost = 0.285643876 \tAcc_Test  : 38.5 \tAcc_Train : 93.0\n",
      "[Epoch :   63] \n",
      "cost = 0.28088972 \tAcc_Test  : 36.5 \tAcc_Train : 90.0\n",
      "[Epoch :   64] \n",
      "cost = 0.242809579 \tAcc_Test  : 36.5 \tAcc_Train : 92.2\n",
      "[Epoch :   65] \n",
      "cost = 0.25021562 \tAcc_Test  : 40.5 \tAcc_Train : 93.8\n",
      "[Epoch :   66] \n",
      "cost = 0.222424522 \tAcc_Test  : 34.5 \tAcc_Train : 92.7\n",
      "[Epoch :   67] \n",
      "cost = 0.232460022 \tAcc_Test  : 38.5 \tAcc_Train : 94.1\n",
      "[Epoch :   68] \n",
      "cost = 0.194455534 \tAcc_Test  : 39.5 \tAcc_Train : 95.1\n",
      "[Epoch :   69] \n",
      "cost = 0.189132407 \tAcc_Test  : 39.5 \tAcc_Train : 95.4\n",
      "[Epoch :   70] \n",
      "cost = 0.16116704 \tAcc_Test  : 35.5 \tAcc_Train : 96.1\n",
      "[Epoch :   71] \n",
      "cost = 0.196729898 \tAcc_Test  : 31.0 \tAcc_Train : 91.3\n",
      "[Epoch :   72] \n",
      "cost = 0.2468234 \tAcc_Test  : 37.0 \tAcc_Train : 93.1\n",
      "[Epoch :   73] \n",
      "cost = 0.206323564 \tAcc_Test  : 36.5 \tAcc_Train : 95.8\n",
      "[Epoch :   74] \n",
      "cost = 0.201641291 \tAcc_Test  : 38.0 \tAcc_Train : 96.0\n",
      "[Epoch :   75] \n",
      "cost = 0.15828976 \tAcc_Test  : 38.0 \tAcc_Train : 96.1\n",
      "[Epoch :   76] \n",
      "cost = 0.131348699 \tAcc_Test  : 34.5 \tAcc_Train : 97.4\n",
      "[Epoch :   77] \n",
      "cost = 0.124869987 \tAcc_Test  : 35.0 \tAcc_Train : 97.0\n",
      "[Epoch :   78] \n",
      "cost = 0.125668123 \tAcc_Test  : 37.0 \tAcc_Train : 96.6\n",
      "[Epoch :   79] \n",
      "cost = 0.140902922 \tAcc_Test  : 32.0 \tAcc_Train : 96.4\n",
      "[Epoch :   80] \n",
      "cost = 0.1461633 \tAcc_Test  : 40.0 \tAcc_Train : 97.4\n",
      "[Epoch :   81] \n",
      "cost = 0.113294899 \tAcc_Test  : 37.5 \tAcc_Train : 98.2\n",
      "[Epoch :   82] \n",
      "cost = 0.106959581 \tAcc_Test  : 35.0 \tAcc_Train : 97.9\n",
      "[Epoch :   83] \n",
      "cost = 0.113290243 \tAcc_Test  : 38.0 \tAcc_Train : 96.0\n",
      "[Epoch :   84] \n",
      "cost = 0.100446254 \tAcc_Test  : 33.0 \tAcc_Train : 97.1\n",
      "[Epoch :   85] \n",
      "cost = 0.0806727856 \tAcc_Test  : 40.5 \tAcc_Train : 97.3\n",
      "[Epoch :   86] \n",
      "cost = 0.0947890952 \tAcc_Test  : 38.5 \tAcc_Train : 98.7\n",
      "[Epoch :   87] \n",
      "cost = 0.10832233 \tAcc_Test  : 37.5 \tAcc_Train : 98.0\n",
      "[Epoch :   88] \n",
      "cost = 0.078109853 \tAcc_Test  : 35.0 \tAcc_Train : 96.6\n",
      "[Epoch :   89] \n",
      "cost = 0.0799635798 \tAcc_Test  : 37.5 \tAcc_Train : 98.4\n",
      "[Epoch :   90] \n",
      "cost = 0.0467289351 \tAcc_Test  : 34.5 \tAcc_Train : 99.0\n",
      "[Epoch :   91] \n",
      "cost = 0.0420269743 \tAcc_Test  : 36.0 \tAcc_Train : 99.5\n",
      "[Epoch :   92] \n",
      "cost = 0.0497233197 \tAcc_Test  : 34.5 \tAcc_Train : 99.1\n",
      "[Epoch :   93] \n",
      "cost = 0.041009374 \tAcc_Test  : 37.5 \tAcc_Train : 99.3\n",
      "[Epoch :   94] \n",
      "cost = 0.0568905734 \tAcc_Test  : 36.5 \tAcc_Train : 98.3\n",
      "[Epoch :   95] \n",
      "cost = 0.061327517 \tAcc_Test  : 35.5 \tAcc_Train : 98.3\n",
      "[Epoch :   96] \n",
      "cost = 0.0600651279 \tAcc_Test  : 38.0 \tAcc_Train : 99.2\n",
      "[Epoch :   97] \n",
      "cost = 0.0610515624 \tAcc_Test  : 36.0 \tAcc_Train : 99.1\n",
      "[Epoch :   98] \n",
      "cost = 0.0402163342 \tAcc_Test  : 37.0 \tAcc_Train : 98.8\n",
      "[Epoch :   99] \n",
      "cost = 0.0420046896 \tAcc_Test  : 34.5 \tAcc_Train : 98.8\n",
      "[Epoch :  100] \n",
      "cost = 0.0403102189 \tAcc_Test  : 35.0 \tAcc_Train : 99.1\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(inputs)\n",
    "        cost = criterion(hypothesis, labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    test_acc  = acc_check(model, test_loader, epoch)\n",
    "    train_acc = acc_check(model, train_loader, epoch)\n",
    "    print('[Epoch : {:>4}] '.format(epoch + 1))\n",
    "    print('cost = {:>.9} \\tAcc_Test  : {:>.3} \\tAcc_Train : {:>.3}'.format(avg_cost,test_acc, train_acc))\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 200 test images: 35 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 200 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 200 train images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 200 train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
